{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep_optimal_stopping.ipynb\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import cholesky\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.stats import norm\n",
    "\n",
    "# 配置\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StoppingPolicy(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    3层神经网络,包含批量归一化和Xavier初始化\n",
    "    结构符合论文第2.2节描述\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim=40):\n",
    "        super().__init__()\n",
    "        self.net = torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_dim, hidden_dim),\n",
    "            torch.nn.BatchNorm1d(hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_dim, hidden_dim),\n",
    "            torch.nn.BatchNorm1d(hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_dim, 1),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "        # Xavier初始化\n",
    "        for layer in self.net:\n",
    "            if isinstance(layer, torch.nn.Linear):\n",
    "                torch.nn.init.xavier_normal_(layer.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PathGenerator:\n",
    "    \"\"\"路径生成的抽象基类\"\"\"\n",
    "    def __init__(self, d, steps, T):\n",
    "        self.d = d          # 维度\n",
    "        self.steps = steps  # 时间步数\n",
    "        self.T = T         # 总时间\n",
    "\n",
    "    def generate(self, n_paths):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlackScholesGenerator(PathGenerator):\n",
    "    \"\"\"\n",
    "    多维Black-Scholes路径生成器\n",
    "    精确实现论文第4.1节的参数设置\n",
    "    \"\"\"\n",
    "    def __init__(self, d, steps, T, r, sigma, rho, div):\n",
    "        super().__init__(d, steps, T)\n",
    "        self.r = r\n",
    "        self.sigma = sigma\n",
    "        self.rho = rho\n",
    "        self.div = div\n",
    "        self.dt = T / steps\n",
    "        self.drift = (self.r - self.div - 0.5 * self.sigma**2) * self.dt  # 新增此行\n",
    "        self._build_cov_matrix()\n",
    "        \n",
    "    def _build_cov_matrix(self):\n",
    "        \"\"\"构建相关系数矩阵\"\"\"\n",
    "        cov = np.eye(self.d) * (self.sigma**2 * self.dt)\n",
    "        cov += (np.ones((self.d, self.d)) * (self.rho * self.sigma**2 * self.dt))\n",
    "        np.fill_diagonal(cov, self.sigma**2 * self.dt)\n",
    "        self.L = torch.tensor(cholesky(cov, lower=True), device=device, dtype=torch.float32) \n",
    "        \n",
    "    def generate(self, n_paths):\n",
    "        \"\"\"生成路径 如有GPU可加速 \"\"\"\n",
    "        paths = torch.zeros(n_paths, self.steps+1, self.d, device=device, dtype=torch.float32)\n",
    "        paths[:, 0] = 100.0  # 初始价格\n",
    "        \n",
    "        noise = torch.randn(n_paths, self.steps, self.d, device=device)\n",
    "        \n",
    "        sqrt_dt = torch.tensor(np.sqrt(self.dt), device=device, dtype=torch.float32)\n",
    "        with tqdm(total=self.steps, desc=\"生成Black-Scholes路径\", leave=False) as pbar:\n",
    "            for t in range(1, self.steps+1):\n",
    "                increments = self.drift + (self.L @ noise[:, t-1].T).T * sqrt_dt\n",
    "                paths[:, t] = paths[:, t-1] * torch.exp(increments)\n",
    "                pbar.update(1)\n",
    "                \n",
    "        return paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepOptimalStoppingTrainer:\n",
    "    \"\"\"\n",
    "    核心训练引擎\n",
    "    实现论文第2节的递归训练算法\n",
    "    \"\"\"\n",
    "    def __init__(self, generator, hidden_dim=40):\n",
    "        self.generator = generator\n",
    "        self.policies = self._init_policies(hidden_dim)\n",
    "        self.optimizers = [torch.optim.Adam(p.parameters(), lr=0.001) \n",
    "                          for p in self.policies]\n",
    "        \n",
    "    def _init_policies(self, hidden_dim):\n",
    "        input_dim = self.generator.d + 1  # 状态+收益\n",
    "        # 初始化 steps+1 个策略网络（对应时间步 0~steps）\n",
    "        return [StoppingPolicy(input_dim, hidden_dim).to(device)\n",
    "                for _ in range(self.generator.steps + 1)]  # 修改为 steps+1\n",
    "    \n",
    "    def train(self, n_paths=8192, epochs=3000, batch_size=2048):\n",
    "        \"\"\"执行反向递归训练\"\"\"\n",
    "        paths = self.generator.generate(n_paths)\n",
    "        # 从到期日向前递归训练\n",
    "        for step in tqdm(reversed(range(self.generator.steps)), desc=\"Training steps\"):\n",
    "            # 动态计算当前时间步的收益\n",
    "            current_payoff = self._compute_payoffs(paths, start_step=step)[:, step]\n",
    "            X, y = self._prepare_training_data(paths, current_payoff, step)\n",
    "            self._train_single_step(step, X, y, epochs, batch_size)\n",
    "    \n",
    "    def _compute_payoffs(self, paths):\n",
    "        \"\"\"计算各时间步的即时收益（需子类实现）\"\"\"\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def _prepare_training_data(self, paths, current_payoff, step):\n",
    "        \"\"\"准备训练数据（含嵌套蒙特卡洛）\"\"\"\n",
    "        current_state = paths[:, step]\n",
    "        X = torch.cat([current_state, current_payoff.unsqueeze(1)], dim=1)\n",
    "        \n",
    "        # 嵌套蒙特卡洛计算继续价值（传递起始时间步）\n",
    "        continuation = self._nested_mc(paths, step)\n",
    "        y = (current_payoff >= continuation).float()\n",
    "        return X, y\n",
    "\n",
    "    def _nested_mc(self, paths, step, J=1024):\n",
    "        \"\"\"嵌套蒙特卡洛模拟，传递起始时间步\"\"\"\n",
    "        n_paths = paths.size(0)\n",
    "        continuation = torch.zeros(n_paths, device=device)\n",
    "        \n",
    "        with tqdm(total=n_paths, desc=f\"嵌套MC(t={step})\", leave=False) as main_pbar:\n",
    "            for i in range(n_paths):\n",
    "                # 生成J条继续路径（从当前step开始）\n",
    "                new_paths = self._generate_continuations(paths[i, step], step, J)\n",
    "                \n",
    "                # 应用后续策略，传递起始时间步\n",
    "                exercise_times = self._apply_policies(new_paths, start_step=step)\n",
    "                \n",
    "                # 计算继续路径的收益，起始时间步为step\n",
    "                payoffs = self._compute_continuation_payoffs(new_paths, exercise_times, step)\n",
    "                \n",
    "                continuation[i] = payoffs.mean()\n",
    "                main_pbar.update(1)\n",
    "        \n",
    "        return continuation\n",
    "    \n",
    "    def _generate_continuations(self, current_state, step, J):\n",
    "        \"\"\"从当前状态生成继续路径（需子类实现）\"\"\"\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    \n",
    "    def _apply_policies(self, paths, start_step):\n",
    "        \"\"\"应用训练好的策略网络 论文公式5 \"\"\"\n",
    "        exercise_times = torch.full((paths.size(0),), self.generator.steps, device=device)\n",
    "        for t in range(start_step + 1, paths.size(1)):\n",
    "            states = paths[:, t]\n",
    "            #print(\"是这里吗\")\n",
    "            # 动态计算当前时间步的收益，起始时间步为start_step\n",
    "            payoffs = self._compute_payoffs(\n",
    "                paths[:, :t+1],  # 截取到当前时间步的路径\n",
    "                start_step=start_step\n",
    "            )[:, t - start_step]  # 局部时间步索引\n",
    "            \n",
    "            inputs = torch.cat([states, payoffs.unsqueeze(1)], dim=1)\n",
    "            stop_probs = self.policies[t](inputs).squeeze()\n",
    "            stop_decisions = (stop_probs >= 0.5).float()\n",
    "            \n",
    "            mask = (exercise_times == self.generator.steps) & (stop_decisions == 1)\n",
    "            exercise_times[mask] = t\n",
    "        \n",
    "        return exercise_times\n",
    "    \n",
    "        \n",
    "    def _train_single_step(self, step, X, y, epochs, batch_size):\n",
    "        \"\"\"训练单个时间步的策略网络\"\"\"\n",
    "        dataset = torch.utils.data.TensorDataset(X, y)\n",
    "        loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        for epoch in tqdm(range(epochs), desc=f\"Training step {step}\", leave=False):\n",
    "            for batch_X, batch_y in loader:\n",
    "                self.optimizers[step].zero_grad()\n",
    "                pred = self.policies[step](batch_X).squeeze()\n",
    "                loss = torch.nn.BCELoss()(pred, batch_y)\n",
    "                loss.backward()\n",
    "                self.optimizers[step].step()\n",
    "\n",
    "    def compute_lower_bound(self, n_paths=4096000, conf_level=0.95):\n",
    "        \"\"\"计算下界及置信区间 论文3.1节 \"\"\"\n",
    "        # 生成独立路径集\n",
    "        test_paths = self.generator.generate(n_paths)\n",
    "        \n",
    "        # 应用训练好的策略确定停止时间\n",
    "        exercise_times = self._apply_policies(test_paths, 0)\n",
    "        \n",
    "        # 收集收益\n",
    "        payoffs = torch.zeros(n_paths, device=device)\n",
    "        for i in range(n_paths):\n",
    "            t = int(exercise_times[i].item())\n",
    "            payoffs[i] = self._compute_payoffs(test_paths[i:i+1])[0, t]\n",
    "        \n",
    "        # 计算统计量\n",
    "        mean = payoffs.mean().item()\n",
    "        std = payoffs.std(unbiased=True).item()\n",
    "        z = 1.96 if conf_level == 0.95 else norm.ppf((1 + conf_level)/2)\n",
    "        ci_half = z * std / np.sqrt(n_paths)\n",
    "        \n",
    "        return {\n",
    "            'estimate': mean,\n",
    "            'lower': mean - ci_half,\n",
    "            'upper': mean + ci_half,\n",
    "            'std': std\n",
    "        }\n",
    "\n",
    "    def compute_upper_bound(self, n_paths=1024, J=16384, conf_level=0.95):\n",
    "        \"\"\"计算上界及置信区间 论文3.2节双重方法\"\"\"\n",
    "        # 生成主路径\n",
    "        primary_paths = self.generator.generate(n_paths)\n",
    "        payoffs = self._compute_payoffs(primary_paths)\n",
    "        \n",
    "        # 初始化Martingale\n",
    "        M = torch.zeros(n_paths, self.generator.steps+1, device=device)\n",
    "        \n",
    "        # 计算Martingale过程\n",
    "        with tqdm(total=self.generator.steps, desc=\"计算上界(Martingale)\") as total_pbar:\n",
    "            for t in range(self.generator.steps):\n",
    "                # 生成J条继续路径\n",
    "                cont_paths = torch.zeros(\n",
    "                                            n_paths, \n",
    "                                            J, \n",
    "                                            self.generator.steps - t, \n",
    "                                            self.generator.d,  # 添加资产维度\n",
    "                                            device=device\n",
    "                                        )\n",
    "                \n",
    "                with tqdm(total=n_paths, desc=f\"时间步 {t}\", leave=False) as sub_pbar:\n",
    "                    for i in range(n_paths):\n",
    "                        cont_paths[i] = self._generate_continuations(primary_paths[i,t], t, J)\n",
    "                        sub_pbar.update(1)\n",
    "                \n",
    "                # 计算继续价值\n",
    "                total_pbar.update(1)\n",
    "                cont_values = torch.zeros(n_paths, device=device)\n",
    "                for i in range(n_paths):\n",
    "                    ex_times = self._apply_policies(cont_paths[i], t)\n",
    "                    cont_values[i] = self._compute_continuation_payoffs(\n",
    "                                                                            cont_paths[i], \n",
    "                                                                            ex_times, \n",
    "                                                                            current_step=t  # 传入当前时间步 t\n",
    "                                                                        ).mean()\n",
    "                \n",
    "                # 更新Martingale\n",
    "                current_payoff = payoffs[:,t]\n",
    "                delta_M = (current_payoff >= cont_values).float() * (current_payoff - cont_values)\n",
    "                M[:,t+1] = M[:,t] + delta_M\n",
    "        \n",
    "        # 计算调整后的收益\n",
    "        adjusted = payoffs - M\n",
    "        max_values, _ = torch.max(adjusted, dim=1)\n",
    "        \n",
    "        # 计算统计量\n",
    "        mean = max_values.mean().item()\n",
    "        std = max_values.std(unbiased=True).item()\n",
    "        z = 1.96 if conf_level == 0.95 else norm.ppf((1 + conf_level)/2)\n",
    "        ci_half = z * std / np.sqrt(n_paths)\n",
    "        \n",
    "        return {\n",
    "            'estimate': mean,\n",
    "            'lower': mean - ci_half,\n",
    "            'upper': mean + ci_half,\n",
    "            'std': std\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BermudanMaxCallTrainer(DeepOptimalStoppingTrainer):\n",
    "    \"\"\"实现论文第4.1节的Bermudan Max-Call实验\"\"\"\n",
    "    def _compute_payoffs(self, paths, start_step=0):\n",
    "        #print(\"bingo?\")\n",
    "        print(f\"path shape:{paths.shape}\")\n",
    "        max_values, _ = torch.max(paths, dim=2)  # (n_paths, steps_remaining+1)\n",
    "        steps_remaining = paths.size(1) - 1  # 路径的局部时间步数\n",
    "        \n",
    "        # 动态生成时间点：从 start_step 到总时间 T\n",
    "        start_time = start_step * self.generator.dt  # 起始时间 = 起始步数 * 时间间隔\n",
    "        time_points = torch.linspace(start_time,self.generator.T,steps_remaining + 1, device=device)\n",
    "        discounts = torch.exp(-self.generator.r * time_points)\n",
    "        #print(max_values.shape)\n",
    "        #print(discounts.shape)\n",
    "        result = (max_values - 100).clamp(min=0) * discounts #k=100\n",
    "        #print(\"bingo\")\n",
    "        return result\n",
    "    \n",
    "    def _generate_continuations(self, current_state, step, J):\n",
    "        \"\"\"生成继续路径，时间步数 = generator.steps - step\"\"\"\n",
    "        steps_remaining = self.generator.steps - step\n",
    "        new_paths = torch.zeros(J, steps_remaining, self.generator.d, device=device)\n",
    "        new_paths[:, 0] = current_state\n",
    "        \n",
    "        for t in range(1, steps_remaining):\n",
    "            Z = torch.randn(J, self.generator.d, device=device)\n",
    "            increments = self.generator.drift + (self.generator.L @ Z.T).T * np.sqrt(self.generator.dt)\n",
    "            new_paths[:, t] = new_paths[:, t-1] * torch.exp(increments)\n",
    "        return new_paths\n",
    "\n",
    "    def _compute_continuation_payoffs(self, new_paths, exercise_times, current_step):\n",
    "        batch_size, steps_remaining, _ = new_paths.shape\n",
    "        \n",
    "        # 动态生成时间点：从当前步骤开始，到总时间T，共 steps_remaining + 1 个点\n",
    "        start_time = current_step * self.generator.dt\n",
    "        time_points = torch.linspace(\n",
    "            start_time, \n",
    "            self.generator.T, \n",
    "            steps_remaining + 1,  # 包含当前时间步和后续所有步\n",
    "            device=device\n",
    "        )\n",
    "        discounts = torch.exp(-self.generator.r * time_points)[1:]  # 排除当前时间步\n",
    "        #print(discounts)\n",
    "        \n",
    "        # 计算收益\n",
    "        max_values, _ = torch.max(new_paths, dim=2)  # 形状 (batch_size, steps_remaining)\n",
    "        payoffs = (max_values - 100).clamp(min=0) * discounts  # 维度必须一致\n",
    "        #print(discounts.shape)\n",
    "        #print(max_values.shape)\n",
    "        \n",
    "        # 按停止时间提取收益\n",
    "        selected_payoffs = torch.zeros(batch_size, device=device)\n",
    "        for i in range(batch_size):\n",
    "            absolute_t = int(exercise_times[i].item())\n",
    "            relative_t = absolute_t - current_step - 1  # 转换为继续路径的局部索引\n",
    "            \n",
    "            # 检查索引是否越界\n",
    "            if relative_t < 0 or relative_t >= steps_remaining:\n",
    "                raise ValueError(\n",
    "                    f\"Invalid exercise time {absolute_t} at step {current_step}. \"\n",
    "                    f\"Relative index must be in [0, {steps_remaining - 1}]\"\n",
    "                )\n",
    "            \n",
    "            selected_payoffs[i] = payoffs[i, relative_t]\n",
    "        \n",
    "        return selected_payoffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MBRCGenerator(BlackScholesGenerator):\n",
    "    \"\"\"带股息支付和障碍监测的路径生成器\"\"\"\n",
    "    def __init__(self, d, steps, T, r, sigma, rho, div_dates, div_rates, barriers):\n",
    "        super().__init__(d, steps, T, r, sigma, rho, div=0)\n",
    "        self.div_dates = div_dates  # 股息支付时间索引列表\n",
    "        self.div_rates = div_rates  # 各资产股息率\n",
    "        self.barriers = barriers    # 障碍水平（百分比）\n",
    "\n",
    "    def generate(self, n_paths):\n",
    "        paths = super().generate(n_paths)\n",
    "        # 检查股息支付时间步是否在路径范围内\n",
    "        for t in self.div_dates:\n",
    "            if t >= self.steps:\n",
    "                raise ValueError(f\"Dividend date {t} exceeds path steps {self.steps}\")\n",
    "            paths[:, t+1:] *= (1 - torch.tensor(self.div_rates, device=device))\n",
    "        return paths\n",
    "\n",
    "    def track_barriers(self, paths):\n",
    "        \"\"\"监测障碍事件（适配局部路径的时间窗口）\"\"\"\n",
    "        barrier_hit = torch.zeros_like(paths[:, :, 0], dtype=torch.bool)\n",
    "        for t_local in range(paths.size(1)):  # 局部时间步\n",
    "            current_min = torch.min(paths[:, t_local, :], dim=1).values\n",
    "            barrier_hit[:, t_local] = (current_min <= self.barriers * 100)\n",
    "        return barrier_hit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CallableMBRCTrainer(DeepOptimalStoppingTrainer):\n",
    "    \"\"\"MBRC训练器 最小化发行人成本\"\"\"\n",
    "    def __init__(self, generator, coupon_rate, nominal=100):\n",
    "        super().__init__(generator)\n",
    "        self.coupon = coupon_rate * generator.T / generator.steps\n",
    "        self.nominal = nominal\n",
    "\n",
    "    def _compute_payoffs(self, paths, start_step=0):\n",
    "        barrier_indicator = self.generator.track_barriers(paths)\n",
    "        n_paths, total_time_steps, _ = paths.shape\n",
    "        \n",
    "        start_time = start_step * self.generator.dt\n",
    "        time_points = torch.linspace(\n",
    "            start_time,\n",
    "            self.generator.T,\n",
    "            total_time_steps,\n",
    "            device=device\n",
    "        )\n",
    "        discounts = torch.exp(-self.generator.r * time_points)\n",
    "        \n",
    "        payoffs = torch.zeros(n_paths, total_time_steps, device=device)\n",
    "        \n",
    "        for t in range(total_time_steps):\n",
    "            global_t = start_step + t\n",
    "            global_t = min(global_t, self.generator.steps)  # 确保不越界\n",
    "            \n",
    "            \n",
    "            coupon_part = self.coupon * (global_t + 1)\n",
    "            \n",
    "            if global_t == self.generator.steps:\n",
    "                final_prices = paths[:, t, :]\n",
    "                min_price = torch.min(final_prices, dim=1).values\n",
    "                # 使用 torch.minimum 替换 torch.min\n",
    "                payoff = torch.where(\n",
    "                    barrier_indicator[:, global_t],\n",
    "                    torch.minimum(min_price, torch.tensor(self.nominal, device=device)),\n",
    "                    self.nominal\n",
    "                )\n",
    "            else:\n",
    "                payoff = self.nominal\n",
    "            \n",
    "            payoffs[:, t] = (coupon_part + payoff) * discounts[t]\n",
    "        \n",
    "        return payoffs\n",
    "    \n",
    "    def _generate_continuations(self, current_state, step, J):\n",
    "        \"\"\"生成考虑股息的继续路径\"\"\"\n",
    "        new_paths = torch.zeros(J, self.generator.steps-step, self.generator.d, device=device)\n",
    "        new_paths[:, 0] = current_state\n",
    "        \n",
    "        for t in range(1, self.generator.steps-step):\n",
    "            Z = torch.randn(J, self.generator.d, device=device)\n",
    "            increments = self.generator.drift + (self.generator.L @ Z.T).T * np.sqrt(self.generator.dt)\n",
    "            new_paths[:, t] = new_paths[:, t-1] * torch.exp(increments)\n",
    "            \n",
    "            # 应用股息支付\n",
    "            if (step + t) in self.generator.div_dates:\n",
    "                new_paths[:, t:] *= (1 - torch.tensor(self.generator.div_rates, device=device))\n",
    "        \n",
    "        return new_paths\n",
    "\n",
    "    def _compute_continuation_payoffs(self, new_paths, exercise_times, current_step):\n",
    "        barrier_indicator = self.generator.track_barriers(new_paths)\n",
    "        batch_size, steps_remaining, _ = new_paths.shape\n",
    "        \n",
    "        start_time = current_step * self.generator.dt\n",
    "        time_points = torch.linspace(\n",
    "            start_time,\n",
    "            self.generator.T,\n",
    "            steps_remaining + 1,\n",
    "            device=device\n",
    "        )\n",
    "        discounts = torch.exp(-self.generator.r * time_points)[1:]\n",
    "        \n",
    "        payoffs = torch.zeros(batch_size, device=device)\n",
    "        for i in range(batch_size):\n",
    "            t = int(exercise_times[i].item())\n",
    "            relative_t = t - current_step - 1\n",
    "            \n",
    "            if relative_t < 0 or relative_t >= steps_remaining:\n",
    "                raise ValueError(f\"Invalid exercise time {t} at step {current_step}\")\n",
    "            \n",
    "            # 全局时间步截断\n",
    "            global_t = min(current_step + relative_t + 1, self.generator.steps)\n",
    "            \n",
    "            coupon_part = self.coupon * (global_t + 1)\n",
    "            \n",
    "            if global_t == self.generator.steps:\n",
    "                final_prices = new_paths[i, relative_t, :]\n",
    "                min_price = torch.min(final_prices)\n",
    "                payoff = torch.where(\n",
    "                    barrier_indicator[i, relative_t],  # 使用局部索引\n",
    "                    torch.minimum(min_price, torch.tensor(self.nominal, device=device)),\n",
    "                    self.nominal\n",
    "                )\n",
    "            else:\n",
    "                payoff = self.nominal\n",
    "            \n",
    "            discounted_payoff = (coupon_part + payoff) * discounts[relative_t]\n",
    "            payoffs[i] = discounted_payoff\n",
    "        \n",
    "        return payoffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FBMGenerator(PathGenerator):\n",
    "    \"\"\"分数布朗运动生成器（带状态嵌入）\"\"\"\n",
    "    def __init__(self, H, steps, T):\n",
    "        super().__init__(steps+1, steps, T)  # 状态维度=时间步数\n",
    "        self.H = H\n",
    "        self._build_cov_matrix()\n",
    "    \n",
    "    def _build_cov_matrix(self):\n",
    "        t = np.linspace(0, self.T, self.steps+1)\n",
    "        cov = 0.5 * (\n",
    "            t[:, None]**(2 * self.H) \n",
    "            + t[None, :]**(2 * self.H) \n",
    "            - np.abs(t[:, None] - t[None, :])**(2 * self.H)\n",
    "        )\n",
    "        np.fill_diagonal(cov, cov.diagonal() + 1e-6)\n",
    "        \n",
    "        # 转换为PyTorch张量并保存\n",
    "        self.cov_matrix = torch.tensor(\n",
    "            cov.astype(np.float32),  # 先转换为float32的NumPy数组\n",
    "            device=device,\n",
    "            dtype=torch.float32       # 再转为PyTorch张量\n",
    "        )\n",
    "        \n",
    "        # Cholesky分解\n",
    "        self.L = torch.linalg.cholesky(self.cov_matrix)\n",
    "        \n",
    "    def generate(self, n_paths):\n",
    "        paths = torch.zeros(n_paths, self.steps+1, device=device, dtype=torch.float32)\n",
    "        for i in range(n_paths):\n",
    "            Z = torch.randn(self.steps+1, device=device, dtype=torch.float32)\n",
    "            paths[i] = self.L @ Z\n",
    "        \n",
    "        # 关键：生成三维嵌入路径，形状 (n_paths, steps+1, steps+1)\n",
    "        embedded = torch.zeros(n_paths, self.steps+1, self.steps+1, device=device)\n",
    "        for t in range(self.steps+1):\n",
    "            embedded[:, t, :t+1] = paths[:, :t+1]  # 填充完整历史状态\n",
    "        return embedded\n",
    "\n",
    "class FBMTrainer(DeepOptimalStoppingTrainer):\n",
    "    \"\"\"分数布朗运动训练器\"\"\"\n",
    "    def __init__(self, H, steps, T, hidden_dim=140):\n",
    "        generator = FBMGenerator(H, steps, T)\n",
    "        super().__init__(generator)\n",
    "        input_dim = (steps + 1) + 1  # 输入维度 = 状态(steps+1) + 收益(1)\n",
    "        self.policies = [\n",
    "            StoppingPolicy(input_dim, hidden_dim).to(device)\n",
    "            for _ in range(steps + 1)\n",
    "        ]\n",
    "        self.optimizers = [torch.optim.Adam(p.parameters(), lr=0.001) for p in self.policies]\n",
    "\n",
    "    def _prepare_training_data(self, paths, current_payoff, step):\n",
    "        # paths形状应为 (n_paths, steps+1, steps+1)\n",
    "        current_state = paths[:, step, :]  # 提取当前时间步的所有历史特征，形状 (n_paths, steps+1)\n",
    "        X = torch.cat([current_state, current_payoff.unsqueeze(1)], dim=1)  # 形状 (n_paths, steps+2)\n",
    "        continuation = self._nested_mc(paths, step)\n",
    "        y = (current_payoff >= continuation).float()\n",
    "        return X, y\n",
    "\n",
    "    def _apply_policies(self, paths, start_step):\n",
    "        exercise_times = torch.full((paths.size(0),), self.generator.steps, device=device)\n",
    "        for t in range(start_step + 1, self.generator.steps + 1):\n",
    "            # 检查路径是否包含足够的时间步\n",
    "            if t >= paths.size(1):\n",
    "                break  # 防止越界\n",
    "            \n",
    "            states = paths[:, t, :]\n",
    "            payoffs = self._compute_payoffs(paths[:, :t+1, :], start_step=start_step)[:, t - start_step]\n",
    "            inputs = torch.cat([states, payoffs.unsqueeze(1)], dim=1)\n",
    "            stop_probs = self.policies[t](inputs).squeeze()\n",
    "            stop_decisions = (stop_probs >= 0.5).float()\n",
    "            \n",
    "            mask = (exercise_times == self.generator.steps) & (stop_decisions == 1)\n",
    "            exercise_times[mask] = t\n",
    "        return exercise_times\n",
    "\n",
    "    def _compute_payoffs(self, paths, start_step=0):\n",
    "        \"\"\"从三维路径中提取FBM值\"\"\"\n",
    "        # paths形状应为 (n_paths, steps_remaining+1, features)\n",
    "        n_paths, steps_remaining_plus_1, features = paths.shape\n",
    "        payoffs = torch.zeros(n_paths, steps_remaining_plus_1, device=device)\n",
    "        for t in range(steps_remaining_plus_1):\n",
    "            payoffs[:, t] = paths[:, t, t]  # 提取对角线特征（假设特征在最后一维）\n",
    "        return payoffs\n",
    "\n",
    "    def _generate_continuations(self, current_state, step, J):\n",
    "        \"\"\"生成条件路径（严格匹配步数）\"\"\"\n",
    "        t = step  # 当前时间步（从0开始）\n",
    "        total_steps = self.generator.steps\n",
    "        \n",
    "        # 需要生成的未来步数\n",
    "        future_steps = total_steps - t  # 从 t+1 到 total_steps，共 future_steps 步\n",
    "        \n",
    "        # 获取协方差矩阵\n",
    "        cov = self.generator.cov_matrix  # 形状 (total_steps+1, total_steps+1)\n",
    "        \n",
    "        # 分割协方差矩阵\n",
    "        Sigma11 = cov[:t+1, :t+1]          # 历史路径协方差 (t+1, t+1)\n",
    "        Sigma12 = cov[:t+1, t+1:t+1+future_steps]  # 历史与未来的协方差 (t+1, future_steps)\n",
    "        Sigma22 = cov[t+1:t+1+future_steps, t+1:t+1+future_steps]  # 未来路径协方差 (future_steps, future_steps)\n",
    "        \n",
    "        # 计算条件协方差\n",
    "        Sigma22_1 = Sigma22 - Sigma12.T @ torch.linalg.inv(Sigma11) @ Sigma12\n",
    "        L22 = torch.linalg.cholesky(Sigma22_1)\n",
    "        \n",
    "        # 生成随机噪声\n",
    "        Z = torch.randn(J, future_steps, device=device)\n",
    "        \n",
    "        # 计算均值项和随机项\n",
    "        current_state_truncated = current_state[:t+1]  # 截取到当前时间步（包含t）\n",
    "        mean_part = current_state_truncated @ torch.linalg.pinv(Sigma11) @ Sigma12  # 形状 (1, future_steps)\n",
    "        random_part = (L22 @ Z.T).T  # 形状 (J, future_steps)\n",
    "        \n",
    "        # 合并均值和随机部分\n",
    "        continuation_values = mean_part + random_part  # 形状 (J, future_steps)\n",
    "        \n",
    "        # 初始化三维路径张量 (J, total_steps+1, total_steps+1)\n",
    "        cond_paths = torch.zeros(J, total_steps+1, total_steps+1, device=device)\n",
    "        \n",
    "        # 填充历史路径（第一个特征维度）\n",
    "        cond_paths[:, :t+1, 0] = current_state_truncated.expand(J, -1)\n",
    "        \n",
    "        # 填充未来路径到对应特征位置（从 t+1 开始）\n",
    "        cond_paths[:, t+1:t+1+future_steps, t+1:t+1+future_steps] = continuation_values.unsqueeze(-1)\n",
    "        \n",
    "        return cond_paths\n",
    "    \n",
    "    def _compute_continuation_payoffs(self, new_paths, exercise_times, current_step):\n",
    "        \"\"\"计算继续路径的收益 直接提取FBM值 \"\"\"\n",
    "        payoffs = torch.zeros(new_paths.size(0), device=device)\n",
    "        for i in range(new_paths.size(0)):\n",
    "            t = int(exercise_times[i].item())\n",
    "            # 转换为继续路径的局部索引\n",
    "            relative_t = t - current_step - 1\n",
    "            if relative_t < 0 or relative_t >= new_paths.size(1):\n",
    "                raise ValueError(f\"Invalid exercise time {t} at step {current_step}\")\n",
    "            payoffs[i] = new_paths[i, relative_t, relative_t]  # 提取局部路径的FBM值\n",
    "        return payoffs\n",
    "\n",
    "    def compute_upper_bound(self, n_paths=1024, J=16384, conf_level=0.95):\n",
    "        \"\"\"计算上界（修正继续路径步数）\"\"\"\n",
    "        # 生成主路径\n",
    "        primary_paths = self.generator.generate(n_paths)\n",
    "        payoffs = self._compute_payoffs(primary_paths)\n",
    "        \n",
    "        # 初始化Martingale过程\n",
    "        M = torch.zeros(n_paths, self.generator.steps+1, device=device)\n",
    "        \n",
    "        # 计算Martingale增量\n",
    "        for t in tqdm(range(self.generator.steps), desc=\"计算上界(Martingale)\"):\n",
    "            # 生成继续路径的步数应为 (steps - t)\n",
    "            steps_remaining = self.generator.steps - t\n",
    "            \n",
    "            # 初始化继续路径容器，形状 (n_paths, J, steps_remaining, features)\n",
    "            cont_paths = torch.zeros(\n",
    "                n_paths, J, steps_remaining, self.generator.d,  # 修正步数为 steps_remaining\n",
    "                device=device\n",
    "            )\n",
    "            \n",
    "            # 生成继续路径\n",
    "            for i in range(n_paths):\n",
    "                # 生成从 t 开始的继续路径（步数为 steps_remaining）\n",
    "                full_cont_path = self._generate_continuations(primary_paths[i, t], t, J)\n",
    "                # 截取从 t+1 到 steps 的路径（共 steps_remaining 步）\n",
    "                cont_paths[i] = full_cont_path[:, t+1:t+1+steps_remaining, :]\n",
    "            \n",
    "            # 计算继续价值\n",
    "            cont_values = torch.zeros(n_paths, device=device)\n",
    "            for i in range(n_paths):\n",
    "                ex_times = self._apply_policies(cont_paths[i], t)\n",
    "                cont_values[i] = self._compute_continuation_payoffs(cont_paths[i], ex_times, t).mean()\n",
    "            \n",
    "            # 更新Martingale\n",
    "            current_payoff = payoffs[:, t]\n",
    "            delta_M = (current_payoff >= cont_values).float() * (current_payoff - cont_values)\n",
    "            M[:, t+1] = M[:, t] + delta_M\n",
    "        \n",
    "        # 计算调整后的收益\n",
    "        adjusted = payoffs - M\n",
    "        max_values, _ = torch.max(adjusted, dim=1)\n",
    "        \n",
    "        # 统计量和置信区间计算（保持不变）\n",
    "        mean = max_values.mean().item()\n",
    "        std = max_values.std(unbiased=True).item()\n",
    "        z = 1.96 if conf_level == 0.95 else norm.ppf((1 + conf_level)/2)\n",
    "        ci_half = z * std / np.sqrt(n_paths)\n",
    "        \n",
    "        return {\n",
    "            'estimate': mean,\n",
    "            'lower': mean - ci_half,\n",
    "            'upper': mean + ci_half,\n",
    "            'std': std\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FBMTrainerWithCustomPrepare(DeepOptimalStoppingTrainer):\n",
    "    \"\"\"FBM专用训练器, 完全覆盖所有必要方法\"\"\"\n",
    "    def __init__(self, H, steps, T, hidden_dim=140):\n",
    "        generator = FBMGenerator(H, steps, T)\n",
    "        super().__init__(generator)\n",
    "        input_dim = (steps + 1) + 1  # 输入维度 = 状态(steps+1) + 收益(1)\n",
    "        self.policies = [\n",
    "            StoppingPolicy(input_dim, hidden_dim).to(device)\n",
    "            for _ in range(steps + 1)\n",
    "        ]\n",
    "        self.optimizers = [torch.optim.Adam(p.parameters(), lr=0.001) for p in self.policies]\n",
    "\n",
    "    # -------------------- 核心方法覆盖 --------------------\n",
    "    def _prepare_training_data(self, paths, current_payoff, step):\n",
    "        \"\"\"FBM专用数据准备（保持其他模型不变）\"\"\"\n",
    "        current_state = paths[:, step, :]  # 从三维嵌入路径提取状态\n",
    "        X = torch.cat([current_state, current_payoff.unsqueeze(1)], dim=1)\n",
    "        continuation = self._nested_mc(paths, step)\n",
    "        y = (current_payoff >= continuation).float()\n",
    "        return X, y\n",
    "\n",
    "    def _compute_payoffs(self, paths, start_step=0):\n",
    "        \"\"\"从三维路径中提取FBM值\"\"\"\n",
    "        n_paths, steps_remaining, _ = paths.shape\n",
    "        payoffs = torch.zeros(n_paths, steps_remaining, device=device)\n",
    "        for t in range(steps_remaining):\n",
    "            payoffs[:, t] = paths[:, t, t]  # 关键：提取对角线值\n",
    "        return payoffs\n",
    "\n",
    "    def _generate_continuations(self, current_state, step, J):\n",
    "        \"\"\"生成条件路径（严格三维结构）\"\"\"\n",
    "        t = step + 1\n",
    "        cond_paths = torch.zeros(J, self.generator.steps+1, self.generator.steps+1, device=device)\n",
    "        cond_paths[:, :t, :t] = current_state.expand(J, -1, -1)  # 复制历史路径\n",
    "        \n",
    "        cov = self.generator.cov_matrix\n",
    "        Sigma11 = cov[:t, :t]\n",
    "        Sigma12 = cov[:t, t:]\n",
    "        Sigma22 = cov[t:, t:]\n",
    "        Sigma22_1 = Sigma22 - Sigma12.T @ torch.linalg.inv(Sigma11) @ Sigma12\n",
    "        L22 = torch.linalg.cholesky(Sigma22_1)\n",
    "        \n",
    "        Z = torch.randn(J, self.generator.steps+1 - t, device=device)\n",
    "        cond_paths[:, t:, t:] = (current_state[:t] @ torch.linalg.pinv(Sigma11) @ Sigma12) + (L22 @ Z.T).T\n",
    "        return cond_paths\n",
    "\n",
    "    def _compute_continuation_payoffs(self, new_paths, exercise_times, current_step):\n",
    "        \"\"\"从继续路径中提取收益\"\"\"\n",
    "        payoffs = torch.zeros(new_paths.size(0), device=device)\n",
    "        for i in range(new_paths.size(0)):\n",
    "            t = int(exercise_times[i].item())\n",
    "            relative_t = t - current_step - 1\n",
    "            if 0 <= relative_t < new_paths.size(1):\n",
    "                payoffs[i] = new_paths[i, relative_t, relative_t]\n",
    "            else:\n",
    "                payoffs[i] = 0.0  # 无效时间步处理\n",
    "        return payoffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 实验执行代码\n",
    "# ==============================\n",
    "def run_Bermudan_experiment():\n",
    "    \"\"\"Bermudan实验 对应论文表1/2 \"\"\"\n",
    "    params = {\n",
    "        \"d\": 5,\n",
    "        \"steps\": 9,\n",
    "        \"T\": 3.0,\n",
    "        \"r\": 0.05,\n",
    "        \"sigma\": 0.2,\n",
    "        \"rho\": 0.0,\n",
    "        \"div\": 0.1\n",
    "    }\n",
    "    \n",
    "    # 初始化生成器和训练器\n",
    "    bs_gen = BlackScholesGenerator(**params)\n",
    "    print(\"BlackScholesGenerator steps:\", bs_gen.steps)\n",
    "    trainer = BermudanMaxCallTrainer(bs_gen, hidden_dim=40+params[\"d\"])\n",
    "    \n",
    "    # 训练（3000步，每批8192条路径）\n",
    "    print(\"开始训练...\")\n",
    "    trainer.train(n_paths=81, epochs=300+params[\"d\"],batch_size=2048)#8192,3000\n",
    "    \n",
    "    # 计算上下界\n",
    "    print(\"计算下界...\")\n",
    "    lb_result = trainer.compute_lower_bound(n_paths=4096000)#4096000\n",
    "    print(\"计算上界...\")\n",
    "    ub_result = trainer.compute_upper_bound(n_paths=1024, J=16384) #1024，16384\n",
    "    \n",
    "    # 输出结果\n",
    "    print(f\"\\nBermudan实验结果:\")\n",
    "    print(f\"Lower bound: {lb_result['estimate']:.3f} ({lb_result['lower']:.3f}, {lb_result['upper']:.3f})\")\n",
    "    print(f\"Upper bound: {ub_result['estimate']:.3f} ({ub_result['lower']:.3f}, {ub_result['upper']:.3f})\")\n",
    "    print(f\"95% Confidence Interval: [{lb_result['lower']:.3f}, {ub_result['upper']:.3f}]\")\n",
    "    print(f\"Point Estimate: {(lb_result['estimate'] + ub_result['estimate'])/2:.3f}\")\n",
    "\n",
    "\n",
    "def run_mbrc_experiment():\n",
    "    \"\"\"Callable MBRC实验 对应论文表3 \"\"\"\n",
    "    params = {\n",
    "        \"d\": 5,\n",
    "        \"steps\": 252,       # 252，1年，每日监测\n",
    "        \"T\": 1.0,\n",
    "        \"r\": 0.00,\n",
    "        \"sigma\": 0.2,\n",
    "        \"rho\": 0.0,\n",
    "        \"div_dates\": [126],  # 半年支付股息，126\n",
    "        \"div_rates\": [0.05]*5,\n",
    "        \"barriers\": 0.7      # 70%障碍\n",
    "    }\n",
    "    \n",
    "    mbrc_gen = MBRCGenerator(**params)\n",
    "    trainer = CallableMBRCTrainer(mbrc_gen, coupon_rate=0.07, nominal=100,hidden_dim=40+params[\"d\"])\n",
    "    \n",
    "    print(\"Training Callable MBRC policies...\")\n",
    "    trainer.train(n_paths=8192, epochs=3000+params[\"d\"])#8192,3000\n",
    "    \n",
    "    # 计算上下界\n",
    "    print(\"计算下界...\")\n",
    "    lb_result = trainer.compute_lower_bound(n_paths=4096000)#4096000\n",
    "    print(\"计算上界...\")\n",
    "    ub_result = trainer.compute_upper_bound(n_paths=1024, J=16384)#1024，16384\n",
    "    \n",
    "    \n",
    "    # 输出结果\n",
    "    print(f\"\\nMBRC实验结果:\")\n",
    "    print(f\"Lower bound: {lb_result['estimate']:.3f} ({lb_result['lower']:.3f}, {lb_result['upper']:.3f})\")\n",
    "    print(f\"Upper bound: {ub_result['estimate']:.3f} ({ub_result['lower']:.3f}, {ub_result['upper']:.3f})\")\n",
    "    print(f\"95% Confidence Interval: [{lb_result['upper']:.3f}, {ub_result['lower']:.3f}]\")\n",
    "    print(f\"Point Estimate: {(lb_result['estimate'] + ub_result['estimate'])/2:.3f}\")\n",
    "\n",
    "\n",
    "def run_fbm_experiment(H=0.7):\n",
    "    \"\"\"分数布朗运动实验 对应论文表4 \"\"\"\n",
    "    assert 0 < H < 1, \"Hurst指数必须在 (0, 1) 之间\"\n",
    "    params = {\n",
    "        \"H\": H,\n",
    "        \"steps\": 100,#100\n",
    "        \"T\": 1.0\n",
    "    }\n",
    "    \n",
    "    fbm_gen = FBMGenerator(**params)\n",
    "    trainer = FBMTrainer(**params)\n",
    "    \n",
    "    print(f\"Training FBM (H={H}) policies...\")\n",
    "    trainer.train(n_paths=8192, epochs=3000)#6000\n",
    "    \n",
    "    print(\"计算下界...\")\n",
    "    lb_result = trainer.compute_lower_bound(n_paths=4096000)\n",
    "    print(\"计算上界...\")\n",
    "    ub_result = trainer.compute_upper_bound(n_paths=1024, J=16384 if H != 0.5 else 32768)#16384，32768\n",
    "    \n",
    "    print(f\"\\nFBM最优停止结果(H={H}):\")\n",
    "    print(f\"Lower bound: {lb_result['estimate']:.3f} ({lb_result['lower']:.3f}, {lb_result['upper']:.3f})\")\n",
    "    print(f\"Upper bound: {ub_result['estimate']:.3f} ({ub_result['lower']:.3f}, {ub_result['upper']:.3f})\")\n",
    "    print(f\"95% Confidence Interval: [{lb_result['upper']:.3f}, {ub_result['lower']:.3f}]\")\n",
    "    print(f\"Point Estimate: {(lb_result['estimate'] + ub_result['estimate'])/2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= 运行Bermudan实验 =========\n",
      "BlackScholesGenerator steps: 9\n",
      "开始训练...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b44e9158feee4530b75f2a36ded7ef42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "生成Black-Scholes路径:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "875a41591be241b9996adaf14d07914f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training steps: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c85539fb7e04679846cc33599fa25c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "嵌套MC(t=8):   0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecf52d0f592847eea5b3918bc091b45f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training step 8:   0%|          | 0/305 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de1ef5879fbb4ce687b5bdc172a80d1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "嵌套MC(t=7):   0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2efd290e31be4eab826c4fd9650f7dc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training step 7:   0%|          | 0/305 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91f1e89544bf4a0eac0459cede2053ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "嵌套MC(t=6):   0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bb8ef4ee6ce4c12a76d99bec3edb38b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training step 6:   0%|          | 0/305 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "837d28b11a734905abcea5d37cc0e61e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "嵌套MC(t=5):   0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c28465138044d8daacd11fab282bdc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training step 5:   0%|          | 0/305 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1766e2aecb4145c2bb1280cda5640ad8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "嵌套MC(t=4):   0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56024f3bb605409cb3ba1df02bf5a526",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training step 4:   0%|          | 0/305 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0ecd7111a3d469bb64a7cb588f06fe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "嵌套MC(t=3):   0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c9917c03f8247ebbc7c1555c45adae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training step 3:   0%|          | 0/305 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "020cb9c77b504c6aa0ad249280bfeffd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "嵌套MC(t=2):   0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8418165e40bb43ee970ec297b19d67c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training step 2:   0%|          | 0/305 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6bb5f9eefe340f396cfbc5a3b3b3036",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "嵌套MC(t=1):   0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92ccd59ffdc44ed99ec29e4284bfc1c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training step 1:   0%|          | 0/305 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bb58ec1508749cdbd6a16f6d456ff2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "嵌套MC(t=0):   0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af08f430af37448fb35cae839056a043",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training step 0:   0%|          | 0/305 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "计算下界...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3abc27674254ea1b200a2129d9d14d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "生成Black-Scholes路径:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "计算上界...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6219eb6522d24eaf93e525a307407a91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "生成Black-Scholes路径:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6a4b5c05bd04cf890366219e4de3bc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "计算上界(Martingale):   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0daa35a0d4a14e2eaae23478b57010bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "时间步 0:   0%|          | 0/1024 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "003784b5b4934585ae7e7d24a3715651",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "时间步 1:   0%|          | 0/1024 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "096cf38bf1264794a1c690b0f6e83c91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "时间步 2:   0%|          | 0/1024 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3346c06fc504ff9933eeb12ec302324",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "时间步 3:   0%|          | 0/1024 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97ee91b39bb74217b228e33dcfac61c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "时间步 4:   0%|          | 0/1024 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4fb774882c54a53bacf0ff5351a96a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "时间步 5:   0%|          | 0/1024 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d971762242e74b22abb71e1f1e59e0ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "时间步 6:   0%|          | 0/1024 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52ba08f43b854cc1b0d18d426b9affb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "时间步 7:   0%|          | 0/1024 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4411b4e5a6f4b2d956ceee862d7476f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "时间步 8:   0%|          | 0/1024 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bermudan实验结果:\n",
      "Lower bound: 6.188 (6.184, 6.192)\n",
      "Upper bound: 11.384 (11.007, 11.762)\n",
      "95% Confidence Interval: [6.184, 11.762]\n",
      "Point Estimate: 8.786\n"
     ]
    }
   ],
   "source": [
    "# --- CELL 8: 执行实验 ---\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    print(\"========= Bermudan实验 =========\")\n",
    "    run_Bermudan_experiment()\n",
    "    \n",
    "    '''\n",
    "    print(\"========= Callable MBRC实验 =========\")\n",
    "    run_mbrc_experiment()\n",
    "    \n",
    "    \n",
    "    print(\"\\n========= 分数布朗运动实验 =========\")\n",
    "    for H in [0.01, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5,\n",
    "             0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1.0]:\n",
    "        run_fbm_experiment(H)\n",
    "    '''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_env_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
